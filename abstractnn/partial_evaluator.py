"""
√âvaluateur partiel pour sous-r√©seaux
=====================================

Module pour √©valuer formellement un sous-ensemble de couches d'un r√©seau.
Utile pour tester la soundness sur de grands mod√®les comme VGG16.
"""

import numpy as np
from typing import List, Dict, Tuple, Any, Optional
import torch
import onnxruntime as ort
from .affine_engine import AffineExpressionEngine, AffineExpression
from .onnx_parser import ONNXParser
from .bound_propagator import BoundPropagator
from .relaxer import NonLinearRelaxer


class PartialNetworkEvaluator:
    """√âvaluateur pour sous-r√©seaux"""
    
    def __init__(self, engine: AffineExpressionEngine):
        """
        Initialiser l'√©valuateur partiel
        
        Args:
            engine: Moteur d'expressions affines
        """
        self.engine = engine
        self.relaxer = NonLinearRelaxer()
    
    def create_input_expressions(
        self,
        image: np.ndarray,
        noise_level: float
    ) -> List[AffineExpression]:
        """
        Cr√©er les expressions d'entr√©e avec bruit
        
        Args:
            image: Image d'entr√©e (C, H, W)
            noise_level: Niveau de bruit epsilon
            
        Returns:
            Liste d'expressions affines
        """
        return self.engine.create_input_expressions(image, noise_level)
    
    def propagate_through_layers(
        self,
        expressions: List[AffineExpression],
        layers: List[Dict[str, Any]],
        input_shape: Tuple[int, ...]
    ) -> Tuple[List[AffineExpression], List[Tuple[float, float]]]:
        """
        Propager les expressions √† travers un sous-ensemble de couches
        
        Args:
            expressions: Expressions d'entr√©e
            layers: Liste des couches √† propager
            input_shape: Forme de l'entr√©e (B, C, H, W) ou (C, H, W)
            
        Returns:
            Tuple (expressions_sortie, bornes_interm√©diaires)
        """
        current_expressions = expressions
        current_shape = input_shape
        all_bounds = []
        
        print(f"  Propagation √† travers {len(layers)} couches...")
        print(f"  Forme d'entr√©e initiale : {current_shape}")
        
        for i, layer in enumerate(layers):
            layer_type = layer['type']
            layer_name = layer.get('name', f'layer_{i}')
            
            try:
                if layer_type == 'Conv':
                    print(f"    [Conv] Avant : {len(current_expressions)} exprs, shape={current_shape}")
                    current_expressions, current_shape = self._propagate_conv(
                        current_expressions,
                        layer,
                        current_shape
                    )
                    print(f"    ‚úì Conv {layer_name}: {len(current_expressions)} exprs, shape={current_shape}")
                    
                elif layer_type == 'Relu':
                    print(f"    [ReLU] Avant : {len(current_expressions)} exprs")
                    current_expressions = self._propagate_relu(current_expressions)
                    print(f"    ‚úì ReLU {layer_name}: {len(current_expressions)} exprs")
                    
                elif layer_type == 'MaxPool':
                    print(f"    [MaxPool] Avant : {len(current_expressions)} exprs, shape={current_shape}")
                    current_expressions, current_shape = self._propagate_maxpool(
                        current_expressions,
                        layer,
                        current_shape
                    )
                    print(f"    ‚úì MaxPool {layer_name}: {len(current_expressions)} exprs, shape={current_shape}")
                    
                elif layer_type == 'Gemm':
                    print(f"    [Gemm] Avant : {len(current_expressions)} exprs")
                    current_expressions = self._propagate_gemm(
                        current_expressions,
                        layer
                    )
                    print(f"    ‚úì Gemm {layer_name}: {len(current_expressions)} exprs")
                    
                elif layer_type == 'Reshape':
                    current_shape = self._get_reshape_output_shape(layer, current_shape)
                    print(f"    ‚úì Reshape {layer_name}: {current_shape}")
                    
                elif layer_type in ['Shape', 'Concat']:
                    print(f"    ‚äó Skipping {layer_type} {layer_name} (auxiliary)")
                    continue
                    
                else:
                    print(f"    ‚ö† Type de couche non support√© : {layer_type}")
                    continue
                
                # Calculer les bornes apr√®s chaque couche (limit√© pour perf)
                sample_size = min(100, len(current_expressions))
                bounds = [expr.get_bounds() for expr in current_expressions[:sample_size]]
                all_bounds.extend(bounds)
                
            except ValueError as e:
                print(f"    ‚úó Erreur ValueError lors de la propagation de {layer_type} {layer_name}: {e}")
                print(f"       Debug: current_shape={current_shape}, len(exprs)={len(current_expressions)}")
                raise
            except Exception as e:
                print(f"    ‚úó Erreur lors de la propagation de {layer_type} {layer_name}: {e}")
                print(f"       Type: {type(e).__name__}")
                import traceback
                traceback.print_exc()
                raise
        
        return current_expressions, all_bounds
    
    def _propagate_conv(
        self,
        expressions: List[AffineExpression],
        layer: Dict[str, Any],
        input_shape: Tuple[int, ...]
    ) -> Tuple[List[AffineExpression], Tuple[int, ...]]:
        """Propager √† travers une couche convolutionnelle"""
        weights = layer.get('weights')
        bias = layer.get('bias')
        
        if weights is None:
            raise ValueError("Conv layer sans poids")
        
        # Extraire les attributs
        attrs = layer.get('attributes', {})
        strides = attrs.get('strides', [1, 1])
        pads = attrs.get('pads', [0, 0, 0, 0])
        dilations = attrs.get('dilations', [1, 1])
        
        print(f"       Conv params: strides={strides}, pads={pads}, dilations={dilations}")
        print(f"       Weights shape: {weights.shape}")
        print(f"       Input shape: {input_shape}")
        
        # Convertir les pads au format attendu
        if len(pads) == 4:
            padding = (pads[0], pads[1])
        elif len(pads) == 2:
            padding = tuple(pads)
        else:
            padding = (0, 0)
        
        # conv2d_layer ATTEND TOUJOURS (B, C, H, W)
        # Il faut donc toujours ajouter le batch si absent
        if len(input_shape) == 3:
            # (C, H, W) -> (1, C, H, W)
            work_shape = (1,) + input_shape
        elif len(input_shape) == 4:
            # D√©j√† (B, C, H, W)
            work_shape = input_shape
        else:
            raise ValueError(f"Forme d'entr√©e invalide pour Conv: {input_shape}")
        
        print(f"       Work shape (avec batch): {work_shape}, padding={padding}")
        
        try:
            # Appeler conv2d_layer avec la forme (B, C, H, W)
            output_exprs, output_shape = self.engine.conv2d_layer(
                expressions,
                weights,
                bias if bias is not None else np.zeros(weights.shape[0]),
                work_shape,  # TOUJOURS 4 dimensions maintenant
                stride=tuple(strides) if len(strides) == 2 else (strides[0], strides[0]),
                padding=padding,
                dilation=tuple(dilations) if len(dilations) == 2 else (dilations[0], dilations[0])
            )
            
            print(f"       Output: {len(output_exprs)} exprs, shape={output_shape}")
            
            # Si l'entr√©e √©tait (C,H,W), retirer le batch de la sortie
            if len(input_shape) == 3 and len(output_shape) == 4:
                output_shape = output_shape[1:]  # (1, C, H, W) -> (C, H, W)
            
            return output_exprs, output_shape
            
        except Exception as e:
            print(f"       ‚úó Erreur dans conv2d_layer: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _propagate_relu(
        self,
        expressions: List[AffineExpression]
    ) -> List[AffineExpression]:
        """Propager √† travers ReLU"""
        relaxed_exprs = []
        for expr in expressions:
            relaxed = self.relaxer.relu_relaxation(expr, relaxation_type='linear')
            relaxed_exprs.append(relaxed)
        
        return relaxed_exprs
    
    def _propagate_maxpool(
        self,
        expressions: List[AffineExpression],
        layer: Dict[str, Any],
        input_shape: Tuple[int, ...]
    ) -> Tuple[List[AffineExpression], Tuple[int, ...]]:
        """Propager √† travers MaxPool"""
        attrs = layer.get('attributes', {})
        kernel_shape = attrs.get('kernel_shape', [2, 2])
        strides = attrs.get('strides', [2, 2])
        
        output_exprs, output_shape = self.engine.maxpool2d_layer(
            expressions,
            input_shape,
            kernel_size=tuple(kernel_shape),
            stride=tuple(strides)
        )
        
        return output_exprs, output_shape
    
    def _propagate_gemm(
        self,
        expressions: List[AffineExpression],
        layer: Dict[str, Any]
    ) -> List[AffineExpression]:
        """Propager √† travers Gemm (General Matrix Multiplication)"""
        weights = layer.get('weights')
        bias = layer.get('bias')
        
        if weights is None:
            raise ValueError("Gemm layer sans poids")
        
        # Gemm attributes
        attrs = layer.get('attributes', {})
        alpha = attrs.get('alpha', 1.0)
        beta = attrs.get('beta', 1.0)
        transA = attrs.get('transA', 0)
        transB = attrs.get('transB', 0)
        
        # Appliquer transpose si n√©cessaire
        W = weights.T if transB else weights
        
        output_exprs = self.engine.linear_layer(
            expressions,
            W * alpha,
            bias * beta if bias is not None else np.zeros(W.shape[0])
        )
        
        return output_exprs
    
    def _get_reshape_output_shape(
        self,
        layer: Dict[str, Any],
        input_shape: Tuple[int, ...]
    ) -> Tuple[int, ...]:
        """Obtenir la forme de sortie d'une op√©ration Reshape"""
        # Pour l'instant, on retourne la forme d'entr√©e
        # Une vraie impl√©mentation extrairait la forme cible
        attrs = layer.get('attributes', {})
        target_shape = attrs.get('shape', input_shape)
        return tuple(target_shape) if target_shape else input_shape


class ONNXPartialEvaluator:
    """√âvaluateur utilisant ONNX Runtime pour les activations interm√©diaires"""
    
    def __init__(self, model_path: str):
        """
        Initialiser l'√©valuateur ONNX
        
        Args:
            model_path: Chemin vers le mod√®le ONNX
        """
        self.model_path = model_path
        self.session = ort.InferenceSession(model_path)
        self.parser = ONNXParser(model_path)
    
    def extract_intermediate_layer_name(self, num_layers: int) -> Optional[str]:
        """
        Trouver le nom de sortie de la n-i√®me couche dans le mod√®le ONNX
        
        Args:
            num_layers: Nombre de couches √† traverser
            
        Returns:
            Nom du tensor de sortie, ou None si non trouv√©
        """
        all_layers = self.parser.parse()
        target_layers = all_layers[:num_layers]
        
        # Le dernier layer devrait avoir un nom de sortie
        if target_layers:
            last_layer = target_layers[-1]
            # Les noms de sortie ONNX sont souvent stock√©s dans 'outputs'
            outputs = last_layer.get('outputs', [])
            if outputs:
                return outputs[0]
        
        return None
    
    def monte_carlo_sampling_at_layer(
        self,
        image: np.ndarray,
        noise_level: float,
        num_layers: int,
        num_samples: int = 100
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        √âchantillonnage Monte Carlo √† une couche sp√©cifique
        
        Args:
            image: Image d'entr√©e (C, H, W)
            noise_level: Niveau de bruit
            num_layers: Nombre de couches √† traverser
            num_samples: Nombre d'√©chantillons
            
        Returns:
            Tuple (bornes_min, bornes_max) des activations √† la couche sp√©cifi√©e
        """
        print(f"\n  Monte Carlo : extraction des activations √† la couche {num_layers}...")
        
        # STRAT√âGIE : Cr√©er un sous-mod√®le ONNX tronqu√© ou utiliser PyTorch
        # Pour ce prototype, on utilise PyTorch pour extraire les activations
        
        try:
            import torch
            import torchvision.models as models
            
            # Charger VGG16 PyTorch
            vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
            vgg16.eval()
            
            # Extraire le sous-r√©seau correspondant aux num_layers premi√®res couches
            # VGG16 features: 0=Conv, 1=ReLU, 2=Conv, 3=ReLU, 4=MaxPool, ...
            # On compte les vraies couches (Conv, ReLU, MaxPool)
            all_layers = self.parser.parse()
            target_layers = all_layers[:num_layers]
            
            # Compter combien de couches features cela repr√©sente
            # Simplification: on mappe num_layers directement √† l'index features
            feature_index = self._map_to_feature_index(target_layers)
            
            print(f"     ‚Üí Extraction jusqu'√† features[{feature_index}]")
            
            # Cr√©er le sous-mod√®le
            sub_model = torch.nn.Sequential(*list(vgg16.features[:feature_index+1]))
            sub_model.eval()
            
            samples = []
            
            for _ in range(num_samples):
                # G√©n√©rer bruit al√©atoire
                noise = np.random.uniform(-noise_level, noise_level, image.shape).astype(np.float32)
                noisy_image = (image + noise).astype(np.float32)
                
                # Ajouter dimension batch
                if len(noisy_image.shape) == 3:
                    noisy_image = np.expand_dims(noisy_image, axis=0)
                
                # Inf√©rence √† travers le sous-mod√®le
                with torch.no_grad():
                    input_tensor = torch.from_numpy(noisy_image)
                    intermediate_output = sub_model(input_tensor)
                    samples.append(intermediate_output.numpy().flatten())
            
            samples_array = np.array(samples)
            return samples_array.min(axis=0), samples_array.max(axis=0)
            
        except Exception as e:
            print(f"     ‚úó Erreur lors de l'extraction des activations : {e}")
            raise
    
    def _map_to_feature_index(self, layers: List[Dict[str, Any]]) -> int:
        """
        Mapper les couches pars√©es vers l'index dans vgg16.features
        
        Args:
            layers: Liste des couches pars√©es
            
        Returns:
            Index dans vgg16.features
        """
        # VGG16.features contient 31 couches s√©quentielles
        # Pattern: Conv-ReLU-Conv-ReLU-MaxPool (r√©p√©t√©)
        
        feature_idx = -1
        
        for layer in layers:
            layer_type = layer['type']
            
            if layer_type == 'Conv':
                feature_idx += 1  # Conv
                # Chaque Conv est suivie d'un ReLU dans features
            elif layer_type == 'Relu':
                feature_idx += 1  # ReLU
            elif layer_type == 'MaxPool':
                feature_idx += 1  # MaxPool
            elif layer_type in ['Shape', 'Concat', 'Reshape']:
                # Ces couches sont auxiliaires, ne comptent pas
                continue
        
        return feature_idx
    
    def monte_carlo_sampling(self, image, noise_level, num_samples=100):
        """Version originale - garde pour compatibilit√©"""
        return self.monte_carlo_sampling_at_layer(image, noise_level, 999, num_samples)


def verify_partial_soundness(
    model_path: str,
    image: np.ndarray,
    noise_level: float,
    num_layers: int = 5,
    num_mc_samples: int = 100
) -> Dict[str, Any]:
    """
    V√©rifier la soundness sur un sous-r√©seau
    
    Args:
        model_path: Chemin vers le mod√®le ONNX
        image: Image d'entr√©e (C, H, W)
        noise_level: Niveau de bruit
        num_layers: Nombre de couches √† tester
        num_mc_samples: Nombre d'√©chantillons Monte Carlo
        
    Returns:
        Dictionnaire avec les r√©sultats de v√©rification
    """
    print(f"\n{'='*70}")
    print(f"V√©rification de soundness partielle")
    print(f"{'='*70}")
    
    # Parser le mod√®le
    parser = ONNXParser(model_path)
    all_layers = parser.parse()
    layers = all_layers[:num_layers]
    
    print(f"\nMod√®le : {model_path}")
    print(f"Couches √† √©valuer : {len(layers)}")
    print(f"Niveau de bruit : {noise_level}")
    print(f"√âchantillons MC : {num_mc_samples}")
    
    # Cr√©er l'√©valuateur formel
    engine = AffineExpressionEngine()
    evaluator = PartialNetworkEvaluator(engine)
    
    # Propagation formelle
    print(f"\n[1/3] Propagation formelle...")
    input_shape = image.shape
    
    try:
        input_expressions = evaluator.create_input_expressions(image, noise_level)
        print(f"  ‚úì {len(input_expressions)} expressions cr√©√©es")
        
        output_expressions, all_bounds = evaluator.propagate_through_layers(
            input_expressions,
            layers,
            input_shape
        )
        
        # Extraire les bornes finales (limit√© pour perf)
        sample_size = min(100, len(output_expressions))
        formal_bounds = [expr.get_bounds() for expr in output_expressions[:sample_size]]
        
        print(f"  ‚úì Propagation formelle termin√©e")
        print(f"  ‚úì {len(formal_bounds)} bornes calcul√©es")
        
    except Exception as e:
        print(f"  ‚úó Erreur lors de la propagation formelle : {e}")
        return {
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }
    
    # Monte Carlo sampling √Ä LA M√äME COUCHE
    print(f"\n[2/3] √âchantillonnage Monte Carlo (m√™me couche)...")
    onnx_evaluator = ONNXPartialEvaluator(model_path)
    
    try:
        # IMPORTANT : Extraire √† la m√™me couche que la propagation formelle
        mc_min, mc_max = onnx_evaluator.monte_carlo_sampling_at_layer(
            image,
            noise_level,
            num_layers,  # M√™me nombre de couches
            num_mc_samples
        )
        
        # Limiter aux m√™mes indices que formel
        mc_min = mc_min[:sample_size]
        mc_max = mc_max[:sample_size]
        
        print(f"  ‚úì {num_mc_samples} √©chantillons Monte Carlo collect√©s")
        print(f"  ‚úì Activations extraites √† la couche {num_layers}")
        
    except Exception as e:
        print(f"  ‚úó Erreur lors du Monte Carlo : {e}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }
    
    # V√©rification de soundness
    print(f"\n[3/3] V√©rification de soundness...")
    
    soundness_report = {
        'is_sound': True,
        'violations': [],
        'total_outputs': len(formal_bounds),
        'violation_count': 0,
        'max_violation_lower': 0.0,
        'max_violation_upper': 0.0,
        'safety_margins_lower': [],
        'safety_margins_upper': [],
        'coverage_ratio': 0.0
    }
    
    for i, (formal_lower, formal_upper) in enumerate(formal_bounds):
        observed_min = float(mc_min[i])
        observed_max = float(mc_max[i])
        
        # V√©rifier soundness avec tol√©rance num√©rique
        tolerance = 1e-6
        lower_sound = observed_min >= formal_lower - tolerance
        upper_sound = observed_max <= formal_upper + tolerance
        
        is_sound = lower_sound and upper_sound
        
        if not is_sound:
            soundness_report['is_sound'] = False
            soundness_report['violation_count'] += 1
            
            violation = {
                'index': i,
                'observed_min': observed_min,
                'formal_min': float(formal_lower),
                'observed_max': observed_max,
                'formal_max': float(formal_upper),
                'violation_lower': max(0, formal_lower - observed_min),
                'violation_upper': max(0, observed_max - formal_upper)
            }
            
            soundness_report['violations'].append(violation)
            soundness_report['max_violation_lower'] = max(
                soundness_report['max_violation_lower'],
                violation['violation_lower']
            )
            soundness_report['max_violation_upper'] = max(
                soundness_report['max_violation_upper'],
                violation['violation_upper']
            )
        
        # Calculer marges de s√©curit√©
        margin_lower = observed_min - formal_lower
        margin_upper = formal_upper - observed_max
        
        soundness_report['safety_margins_lower'].append(float(margin_lower))
        soundness_report['safety_margins_upper'].append(float(margin_upper))
    
    # Calculer le ratio de couverture
    soundness_report['coverage_ratio'] = (
        1.0 - (soundness_report['violation_count'] / soundness_report['total_outputs'])
    )
    
    # Afficher r√©sum√©
    print(f"\n{'‚îÄ'*70}")
    if soundness_report['is_sound']:
        print(f"‚úÖ SOUND : Toutes les valeurs observ√©es sont dans les bornes formelles")
    else:
        print(f"‚ùå NOT SOUND : {soundness_report['violation_count']} violations d√©tect√©es")
        print(f"   Taux de couverture : {soundness_report['coverage_ratio']*100:.2f}%")
    
    avg_margin_lower = np.mean(soundness_report['safety_margins_lower'])
    avg_margin_upper = np.mean(soundness_report['safety_margins_upper'])
    print(f"\nüìè Marges de s√©curit√© moyennes :")
    print(f"   Borne inf√©rieure : {avg_margin_lower:.6f}")
    print(f"   Borne sup√©rieure : {avg_margin_upper:.6f}")
    
    print(f"\nüí° Comparaison correcte :")
    print(f"   Formel : Bornes apr√®s {num_layers} couches")
    print(f"   Monte Carlo : Activations apr√®s {num_layers} couches")
    print(f"   ‚úÖ M√™me niveau de r√©seau compar√©")
    
    return {
        'success': True,
        'soundness_report': soundness_report,
        'formal_bounds': formal_bounds,
        'monte_carlo_bounds': (mc_min.tolist(), mc_max.tolist()),
        'num_layers': len(layers),
        'num_outputs': len(formal_bounds),
        'noise_level': noise_level,
        'num_mc_samples': num_mc_samples
    }


def quick_soundness_check(
    model_path: str,
    test_image: np.ndarray,
    epsilon: float = 0.01,
    num_layers: int = 5,
    verbose: bool = True
) -> bool:
    """
    V√©rification rapide de soundness
    
    Args:
        model_path: Chemin vers le mod√®le ONNX
        test_image: Image de test (C, H, W)
        epsilon: Niveau de bruit
        num_layers: Nombre de couches √† tester
        verbose: Afficher les d√©tails
        
    Returns:
        True si sound, False sinon
    """
    result = verify_partial_soundness(
        model_path,
        test_image,
        epsilon,
        num_layers=num_layers,
        num_mc_samples=50
    )
    
    if not result['success']:
        if verbose:
            print(f"Erreur : {result['error']}")
        return False
    
    is_sound = result['soundness_report']['is_sound']
    
    if verbose and not is_sound:
        violations = result['soundness_report']['violation_count']
        total = result['soundness_report']['total_outputs']
        print(f"Violations : {violations}/{total}")
    
    return is_sound
